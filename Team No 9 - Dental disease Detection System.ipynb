{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "psv2u7BWBSXQ",
        "outputId": "b208d4d1-ed82-4486-8b89-6a2fe151b0f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import subprocess\n",
        "\n",
        "# Function to install packages\n",
        "def install_packages(packages):\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "            print(f\"Successfully installed {package}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error installing {package}: {e}\")\n",
        "\n",
        "# Install required packages\n",
        "packages_to_install = [\n",
        "    'ultralytics',\n",
        "    'roboflow',\n",
        "    'gradio',\n",
        "    'opencv-python-headless',\n",
        "    'numpy',\n",
        "    'tensorflow'\n",
        "]\n",
        "print(\"Installing required packages...\")\n",
        "install_packages(packages_to_install)\n",
        "print(\"Package installation complete!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UppqgoL7W1z0",
        "outputId": "2277e089-3f7a-422a-f799-6a60493b4441"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing required packages...\n",
            "Successfully installed ultralytics\n",
            "Successfully installed roboflow\n",
            "Successfully installed gradio\n",
            "Successfully installed opencv-python-headless\n",
            "Successfully installed numpy\n",
            "Successfully installed tensorflow\n",
            "Package installation complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "print(\"Mounting Google Drive...\")\n",
        "drive.mount('/content/drive')\n",
        "print(\"Google Drive mounted successfully!\")\n",
        "\n",
        "# Verify the model path exists\n",
        "model_path = '/content/drive/MyDrive/dental_images/best.pt'\n",
        "if os.path.exists(model_path):\n",
        "    print(f\"Model found at: {model_path}\")\n",
        "else:\n",
        "    print(f\"Warning: Model not found at {model_path}\")\n",
        "    print(\"Please ensure your YOLO model is at the correct location in Google Drive\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99bTo3CvXXfZ",
        "outputId": "f8b46da1-05b1-4f75-f5c1-659d5dda99b3"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounting Google Drive...\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Google Drive mounted successfully!\n",
            "Model found at: /content/drive/MyDrive/dental_images/best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing Functions\n",
        "def standardize_image(image):\n",
        "    \"\"\"\n",
        "    Ensure image is in a consistent format:\n",
        "    - Convert to 3-channel BGR if needed\n",
        "    - Resize to a standard size\n",
        "    - Normalize intensity\n",
        "    \"\"\"\n",
        "    # Handle different input types\n",
        "    if image is None:\n",
        "        raise ValueError(\"Invalid image input\")\n",
        "\n",
        "    # Ensure 3 channels\n",
        "    if len(image.shape) == 2:\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_GRAY2BGR)\n",
        "    elif image.shape[2] == 4:  # If RGBA\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_RGBA2BGR)\n",
        "\n",
        "    # Resize to a standard size while maintaining aspect ratio\n",
        "    max_size = 800\n",
        "    h, w = image.shape[:2]\n",
        "    scale = min(max_size/w, max_size/h)\n",
        "    new_w = int(w * scale)\n",
        "    new_h = int(h * scale)\n",
        "\n",
        "    image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
        "\n",
        "    return image\n",
        "\n",
        "def enhance_image(image):\n",
        "    \"\"\"\n",
        "    Enhanced image preprocessing with multiple techniques\n",
        "    \"\"\"\n",
        "    # Standardize image first\n",
        "    image = standardize_image(image)\n",
        "\n",
        "    # Convert to float32 for processing\n",
        "    image = image.astype(np.float32) / 255.0\n",
        "\n",
        "    # Create CLAHE object\n",
        "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
        "\n",
        "    # Convert to LAB color space\n",
        "    lab = cv2.cvtColor((image * 255).astype(np.uint8), cv2.COLOR_BGR2LAB)\n",
        "\n",
        "    # Split the LAB image to different channels\n",
        "    l, a, b = cv2.split(lab)\n",
        "\n",
        "    # Apply CLAHE to L-channel\n",
        "    l_clahe = clahe.apply(l)\n",
        "\n",
        "    # Merge the CLAHE enhanced L-channel with the a and b channel\n",
        "    enhanced_lab = cv2.merge((l_clahe, a, b))\n",
        "\n",
        "    # Convert back to BGR\n",
        "    enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)\n",
        "\n",
        "    return enhanced_image\n",
        "\n",
        "# Test the preprocessing functions with a sample image\n",
        "print(\"Testing preprocessing functions...\")\n",
        "# Create a simple test image\n",
        "test_image = np.ones((300, 300, 3), dtype=np.uint8) * 127\n",
        "# Add some simple shapes for visualization\n",
        "cv2.rectangle(test_image, (50, 50), (250, 250), (200, 100, 100), -1)\n",
        "cv2.circle(test_image, (150, 150), 50, (100, 200, 100), -1)\n",
        "\n",
        "# Process the test image\n",
        "standardized_image = standardize_image(test_image)\n",
        "enhanced_image = enhance_image(test_image)\n",
        "\n",
        "print(f\"Original image shape: {test_image.shape}\")\n",
        "print(f\"Standardized image shape: {standardized_image.shape}\")\n",
        "print(\"Preprocessing functions working correctly!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b0eot2OwXa-R",
        "outputId": "9f269393-0c29-4472-b278-60346ff022ef"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing preprocessing functions...\n",
            "Original image shape: (300, 300, 3)\n",
            "Standardized image shape: (800, 800, 3)\n",
            "Preprocessing functions working correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def jaw_segmentation(image):\n",
        "    \"\"\"\n",
        "    Advanced jaw segmentation that creates proper upper and lower jaw separation\n",
        "    \"\"\"\n",
        "    # Ensure standardized image\n",
        "    image = standardize_image(image)\n",
        "\n",
        "    # Convert to grayscale\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    # Apply contrast enhancement for better feature extraction\n",
        "    clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8,8))\n",
        "    enhanced = clahe.apply(gray)\n",
        "\n",
        "    # Apply noise reduction\n",
        "    blurred = cv2.GaussianBlur(enhanced, (5, 5), 0)\n",
        "\n",
        "    # Apply adaptive thresholding\n",
        "    thresh = cv2.adaptiveThreshold(\n",
        "        blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "        cv2.THRESH_BINARY_INV, 11, 2\n",
        "    )\n",
        "\n",
        "    # Morphological operations to clean up the mask\n",
        "    kernel = np.ones((3, 3), np.uint8)\n",
        "    cleaned = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)\n",
        "    cleaned = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel)\n",
        "\n",
        "    # Find teeth contours\n",
        "    contours, _ = cv2.findContours(\n",
        "        cleaned, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE\n",
        "    )\n",
        "\n",
        "    # Filter contours by size to focus on teeth\n",
        "    min_contour_area = 100\n",
        "    teeth_contours = [cnt for cnt in contours if cv2.contourArea(cnt) > min_contour_area]\n",
        "\n",
        "    if not teeth_contours:\n",
        "        # Fallback if no good contours found\n",
        "        h, w = gray.shape\n",
        "        upper_jaw = np.zeros_like(gray)\n",
        "        upper_jaw[:h//2, :] = gray[:h//2, :]\n",
        "\n",
        "        lower_jaw = np.zeros_like(gray)\n",
        "        lower_jaw[h//2:, :] = gray[h//2:, :]\n",
        "\n",
        "        return upper_jaw, lower_jaw\n",
        "\n",
        "    # Create a mask of detected teeth\n",
        "    teeth_mask = np.zeros_like(gray)\n",
        "    cv2.drawContours(teeth_mask, teeth_contours, -1, 255, -1)\n",
        "\n",
        "    # Determine the separation curve between upper and lower jaws\n",
        "    # First, find the centroid of each contour\n",
        "    centroids = []\n",
        "    for cnt in teeth_contours:\n",
        "        M = cv2.moments(cnt)\n",
        "        if M[\"m00\"] != 0:\n",
        "            cx = int(M[\"m10\"] / M[\"m00\"])\n",
        "            cy = int(M[\"m01\"] / M[\"m00\"])\n",
        "            centroids.append((cx, cy))\n",
        "\n",
        "    # If we can't find centroids, use fallback\n",
        "    if not centroids:\n",
        "        h, w = gray.shape\n",
        "        upper_jaw = np.zeros_like(gray)\n",
        "        upper_jaw[:h//2, :] = gray[:h//2, :]\n",
        "\n",
        "        lower_jaw = np.zeros_like(gray)\n",
        "        lower_jaw[h//2:, :] = gray[h//2:, :]\n",
        "\n",
        "        return upper_jaw, lower_jaw\n",
        "\n",
        "    # Sort centroids by y-coordinate\n",
        "    centroids.sort(key=lambda c: c[1])\n",
        "\n",
        "    # Determine the midpoint between upper and lower teeth\n",
        "    # This approach assumes teeth are roughly in two clusters\n",
        "    if len(centroids) >= 4:  # Need enough points to make a reasonable estimate\n",
        "        # Calculate distances between consecutive y-coordinates\n",
        "        y_diffs = [centroids[i+1][1] - centroids[i][1] for i in range(len(centroids)-1)]\n",
        "\n",
        "        # Find the largest gap - this should be between upper and lower teeth\n",
        "        max_diff_idx = y_diffs.index(max(y_diffs))\n",
        "        separation_y = (centroids[max_diff_idx][1] + centroids[max_diff_idx+1][1]) // 2\n",
        "    else:\n",
        "        # Fallback if we don't have enough centroids\n",
        "        h = gray.shape[0]\n",
        "        separation_y = h // 2\n",
        "\n",
        "    # Create masks for upper and lower jaws\n",
        "    h, w = gray.shape\n",
        "\n",
        "    # Create a smooth separation curve\n",
        "    # Create a curved separation line\n",
        "    curve_points = []\n",
        "    for x in range(0, w, 10):\n",
        "        # Create a slight curve - higher in the middle, lower at the edges\n",
        "        offset = int(20 * np.sin(np.pi * x / w))\n",
        "        curve_y = separation_y - offset\n",
        "        curve_points.append((x, curve_y))\n",
        "\n",
        "    # Interpolate to get a point for every x coordinate\n",
        "    x_values = [p[0] for p in curve_points]\n",
        "    y_values = [p[1] for p in curve_points]\n",
        "\n",
        "    # Use np.interp for linear interpolation\n",
        "    all_x = np.arange(w)\n",
        "    all_y = np.interp(all_x, x_values, y_values).astype(int)\n",
        "\n",
        "    # Create masks based on the curve\n",
        "    upper_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "    lower_mask = np.zeros((h, w), dtype=np.uint8)\n",
        "\n",
        "    # Fill masks based on the separation curve\n",
        "    for x in range(w):\n",
        "        y_sep = all_y[x]\n",
        "        upper_mask[:y_sep, x] = 1\n",
        "        lower_mask[y_sep:, x] = 1\n",
        "\n",
        "    # Apply masks to the original image\n",
        "    upper_jaw = cv2.bitwise_and(gray, gray, mask=upper_mask)\n",
        "    lower_jaw = cv2.bitwise_and(gray, gray, mask=lower_mask)\n",
        "\n",
        "    # Apply the teeth mask as well to highlight only teeth areas\n",
        "    teeth_upper = cv2.bitwise_and(teeth_mask, teeth_mask, mask=upper_mask)\n",
        "    teeth_lower = cv2.bitwise_and(teeth_mask, teeth_mask, mask=lower_mask)\n",
        "\n",
        "    return teeth_upper, teeth_lower\n",
        "\n",
        "# Test the jaw segmentation function\n",
        "print(\"Testing jaw segmentation function...\")\n",
        "# Create a simple test image that mimics a dental X-ray\n",
        "test_dental = np.zeros((400, 300), dtype=np.uint8)\n",
        "# Add upper teeth (white regions in top half)\n",
        "for i in range(5):\n",
        "    x = 50 + i * 40\n",
        "    y = 100\n",
        "    cv2.circle(test_dental, (x, y), 15, 255, -1)\n",
        "# Add lower teeth (white regions in bottom half)\n",
        "for i in range(5):\n",
        "    x = 50 + i * 40\n",
        "    y = 300\n",
        "    cv2.circle(test_dental, (x, y), 15, 255, -1)\n",
        "\n",
        "# Convert to 3-channel image for processing\n",
        "test_dental_bgr = cv2.cvtColor(test_dental, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "# Apply jaw segmentation\n",
        "upper_jaw, lower_jaw = jaw_segmentation(test_dental_bgr)\n",
        "\n",
        "print(f\"Upper jaw shape: {upper_jaw.shape}\")\n",
        "print(f\"Lower jaw shape: {lower_jaw.shape}\")\n",
        "print(\"Jaw segmentation function working correctly!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rN2npag6Xe4O",
        "outputId": "e27aace0-d78a-4ab1-d25e-3847bce07b7f"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing jaw segmentation function...\n",
            "Upper jaw shape: (800, 600)\n",
            "Lower jaw shape: (800, 600)\n",
            "Jaw segmentation function working correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_dental_diseases(image_path):\n",
        "    \"\"\"\n",
        "    Robust disease detection with error handling and returns detection data\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Attempt to load model\n",
        "        model = YOLO('/content/drive/MyDrive/dental_images/best.pt')\n",
        "        print(f\"Model loaded successfully\")\n",
        "\n",
        "        # Detect diseases\n",
        "        results = model(image_path)\n",
        "        print(f\"Detection completed on image: {image_path}\")\n",
        "\n",
        "        # Get detection results\n",
        "        detections = []\n",
        "        for result in results:\n",
        "            boxes = result.boxes\n",
        "            for box in boxes:\n",
        "                cls = int(box.cls.item())\n",
        "                conf = box.conf.item()\n",
        "                category = result.names[cls]\n",
        "                detections.append({\n",
        "                    'category': category,\n",
        "                    'confidence': conf,\n",
        "                    'box': box.xyxy.tolist()[0]  # Convert to list for easier handling\n",
        "                })\n",
        "\n",
        "        # Annotate image with detections\n",
        "        annotated_image = results[0].plot()\n",
        "\n",
        "        return annotated_image, detections\n",
        "    except Exception as e:\n",
        "        print(f\"Detection error: {e}\")\n",
        "        # Return original image if detection fails\n",
        "        if os.path.exists(image_path):\n",
        "            return cv2.imread(image_path), []\n",
        "        else:\n",
        "            return np.zeros((300, 300, 3), dtype=np.uint8), []\n",
        "\n",
        "def create_detection_summary(detections):\n",
        "    \"\"\"\n",
        "    Create a summary image showing the count of different dental findings\n",
        "    \"\"\"\n",
        "    # Count occurrences of each category\n",
        "    category_counts = {}\n",
        "    for detection in detections:\n",
        "        category = detection['category']\n",
        "        if category in category_counts:\n",
        "            category_counts[category] += 1\n",
        "        else:\n",
        "            category_counts[category] = 1\n",
        "\n",
        "    # Create a blank image for the summary\n",
        "    height = 100 + (len(category_counts) * 30)\n",
        "    height = max(height, 200)  # Ensure minimum height\n",
        "    width = 400\n",
        "    summary_image = np.ones((height, width, 3), dtype=np.uint8) * 255\n",
        "\n",
        "    # Add title\n",
        "    cv2.putText(summary_image, \"DETECTION SUMMARY\", (20, 40),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)\n",
        "\n",
        "    # Add separator line\n",
        "    cv2.line(summary_image, (20, 50), (width-20, 50), (0, 0, 0), 1)\n",
        "\n",
        "    # Add category counts\n",
        "    y_pos = 90\n",
        "    if not category_counts:\n",
        "        cv2.putText(summary_image, \"No detections found\", (30, y_pos),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)\n",
        "    else:\n",
        "        for category, count in category_counts.items():\n",
        "            text = f\"{category.capitalize()}: {count}\"\n",
        "            cv2.putText(summary_image, text, (30, y_pos),\n",
        "                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 0), 1)\n",
        "            y_pos += 30\n",
        "\n",
        "    return summary_image\n",
        "\n",
        "# Test the detection summary function\n",
        "print(\"Testing detection summary function...\")\n",
        "# Create some sample detections\n",
        "sample_detections = [\n",
        "    {'category': 'cavity', 'confidence': 0.95, 'box': [10, 10, 50, 50]},\n",
        "    {'category': 'cavity', 'confidence': 0.87, 'box': [60, 60, 100, 100]},\n",
        "    {'category': 'gingivitis', 'confidence': 0.92, 'box': [120, 120, 180, 180]}\n",
        "]\n",
        "\n",
        "# Create a summary\n",
        "summary_image = create_detection_summary(sample_detections)\n",
        "print(f\"Detection summary image shape: {summary_image.shape}\")\n",
        "print(\"Detection summary function working correctly!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Goh4ynn2Xifj",
        "outputId": "f23bfbd3-9a6f-46de-be10-a1b93b336c88"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing detection summary function...\n",
            "Detection summary image shape: (200, 400, 3)\n",
            "Detection summary function working correctly!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dental_disease_pipeline(image_path):\n",
        "    \"\"\"\n",
        "    Comprehensive pipeline with robust error handling\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Read input image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        if image is None:\n",
        "            raise ValueError(\"Unable to read image\")\n",
        "\n",
        "        print(f\"Processing image: {image_path}\")\n",
        "        print(f\"Image shape: {image.shape}\")\n",
        "\n",
        "        # Image enhancement\n",
        "        enhanced_image = enhance_image(image)\n",
        "        print(\"Image enhancement complete\")\n",
        "\n",
        "        # Jaw segmentation\n",
        "        upper_jaw, lower_jaw = jaw_segmentation(enhanced_image)\n",
        "        print(\"Jaw segmentation complete\")\n",
        "\n",
        "        # Disease detection\n",
        "        print(\"Starting disease detection...\")\n",
        "        detection_result, detections = detect_dental_diseases(image_path)\n",
        "        print(f\"Disease detection complete. Found {len(detections)} detections\")\n",
        "\n",
        "        # Create detection summary\n",
        "        detection_summary = create_detection_summary(detections)\n",
        "        print(\"Detection summary created\")\n",
        "\n",
        "        return {\n",
        "            'Original Image': image,\n",
        "            'Enhanced Image': enhanced_image,\n",
        "            'Upper Jaw': upper_jaw,\n",
        "            'Lower Jaw': lower_jaw,\n",
        "            'Disease Detection': detection_result,\n",
        "            'Detection Summary': detection_summary,\n",
        "            'Raw Detections': detections\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"Pipeline error: {e}\")\n",
        "        return None\n",
        "\n",
        "# Create a test image path\n",
        "print(\"Testing pipeline function...\")\n",
        "# Create a temp test image\n",
        "test_path = '/content/test_dental.png'\n",
        "test_img = np.zeros((400, 300, 3), dtype=np.uint8)\n",
        "# Add some shapes\n",
        "cv2.rectangle(test_img, (50, 50), (250, 150), (200, 200, 200), -1)\n",
        "cv2.circle(test_img, (150, 250), 50, (180, 180, 180), -1)\n",
        "cv2.imwrite(test_path, test_img)\n",
        "\n",
        "print(f\"Created test image at: {test_path}\")\n",
        "print(\"Note: The disease detection may show warnings if the model isn't found.\")\n",
        "print(\"This is expected during testing if you haven't yet uploaded your model.\")\n",
        "\n",
        "# Test the pipeline\n",
        "results = dental_disease_pipeline(test_path)\n",
        "if results:\n",
        "    print(\"Pipeline test successful!\")\n",
        "else:\n",
        "    print(\"Pipeline test failed. Check the errors above.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MzEZZpRXlv6",
        "outputId": "4dae6e9f-22c7-49e8-c973-6bfa5479efc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing pipeline function...\n",
            "Created test image at: /content/test_dental.png\n",
            "Note: The disease detection may show warnings if the model isn't found.\n",
            "This is expected during testing if you haven't yet uploaded your model.\n",
            "Processing image: /content/test_dental.png\n",
            "Image shape: (400, 300, 3)\n",
            "Image enhancement complete\n",
            "Jaw segmentation complete\n",
            "Starting disease detection...\n",
            "Model loaded successfully\n",
            "\n",
            "image 1/1 /content/test_dental.png: 640x480 (no detections), 94.1ms\n",
            "Speed: 3.0ms preprocess, 94.1ms inference, 0.7ms postprocess per image at shape (1, 3, 640, 480)\n",
            "Detection completed on image: /content/test_dental.png\n",
            "Disease detection complete. Found 0 detections\n",
            "Detection summary created\n",
            "Pipeline test successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "def gradio_interface(image):\n",
        "    \"\"\"\n",
        "    Gradio interface with comprehensive error handling\n",
        "    \"\"\"\n",
        "    # Temporary save path\n",
        "    temp_path = '/content/temp_upload.png'\n",
        "\n",
        "    try:\n",
        "        # Save uploaded image\n",
        "        cv2.imwrite(temp_path, image)\n",
        "        print(f\"Received image uploaded to: {temp_path}\")\n",
        "\n",
        "        # Process image\n",
        "        print(\"Starting dental disease pipeline...\")\n",
        "        results = dental_disease_pipeline(temp_path)\n",
        "\n",
        "        if results is None:\n",
        "            raise ValueError(\"Processing failed\")\n",
        "\n",
        "        print(\"Processing complete, returning results\")\n",
        "        return [\n",
        "            results['Original Image'],\n",
        "            results['Enhanced Image'],\n",
        "            results['Upper Jaw'],\n",
        "            results['Lower Jaw'],\n",
        "            results['Disease Detection'],\n",
        "            results['Detection Summary']\n",
        "        ]\n",
        "    except Exception as e:\n",
        "        print(f\"Interface error: {e}\")\n",
        "        # Create error images\n",
        "        error_image = np.zeros((300, 300, 3), dtype=np.uint8)\n",
        "        cv2.putText(error_image, str(e), (10, 150),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
        "        return [error_image] * 6\n",
        "\n",
        "print(\"Gradio interface function defined successfully\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IM5QlDByXpU5",
        "outputId": "dc18fc05-1d23-4b52-b6dc-5f99ed34c3b5"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradio interface function defined successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Gradio Interface\n",
        "print(\"Creating Gradio interface...\")\n",
        "iface = gr.Interface(\n",
        "    fn=gradio_interface,\n",
        "    inputs=gr.Image(type=\"numpy\"),\n",
        "    outputs=[\n",
        "        gr.Image(label=\"Original Image\"),\n",
        "        gr.Image(label=\"Enhanced Image\"),\n",
        "        gr.Image(label=\"Upper Jaw\"),\n",
        "        gr.Image(label=\"Lower Jaw\"),\n",
        "        gr.Image(label=\"Disease Detection\"),\n",
        "        gr.Image(label=\"Detection Summary\")\n",
        "    ],\n",
        "    title=\"Dental Disease Detection\",\n",
        "    description=\"Upload a dental X-ray to detect diseases and segment jaw regions.\",\n",
        "    allow_flagging=\"never\"\n",
        ")\n",
        "\n",
        "# Launch the interface\n",
        "print(\"Launching Gradio interface. A link will be provided below:\")\n",
        "iface.launch(debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-4n22qNsXr2b",
        "outputId": "320d25bb-1544-4d01-bb7b-0e9533712559"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Gradio interface...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gradio/interface.py:415: UserWarning: The `allow_flagging` parameter in `Interface` is deprecated.Use `flagging_mode` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Launching Gradio interface. A link will be provided below:\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://66ef1583faf532f3ab.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://66ef1583faf532f3ab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Received image uploaded to: /content/temp_upload.png\n",
            "Starting dental disease pipeline...\n",
            "Processing image: /content/temp_upload.png\n",
            "Image shape: (840, 1615, 3)\n",
            "Image enhancement complete\n",
            "Jaw segmentation complete\n",
            "Starting disease detection...\n",
            "Model loaded successfully\n",
            "\n",
            "image 1/1 /content/temp_upload.png: 352x640 1 Filling, 2 Root Canal Treatments, 1 Bone Loss, 72.4ms\n",
            "Speed: 1.9ms preprocess, 72.4ms inference, 2.5ms postprocess per image at shape (1, 3, 352, 640)\n",
            "Detection completed on image: /content/temp_upload.png\n",
            "Disease detection complete. Found 4 detections\n",
            "Detection summary created\n",
            "Processing complete, returning results\n",
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://66ef1583faf532f3ab.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}